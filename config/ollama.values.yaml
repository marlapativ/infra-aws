ollama:
  enabled: true
  fullnameOverride: 'open-webui-ollama'
  podAnnotations:
    sidecar.istio.io/inject: 'false'
  ollama:
    gpu:
      enabled: true
      type: 'nvidia'
      number: 1
    models:
      - gemma:2b
      - mxbai-embed-large:latest
  resources:
    requests:
      memory: 4096Mi
      cpu: 2000m
    limits:
      memory: 7000Mi
      cpu: 3500m
  persistentVolume:
    enabled: true
  tolerations:
    - key: 'nvidia.com/gpu'
      operator: 'Exists'
      effect: 'NoSchedule'
pipelines:
  enabled: true
  image:
    repository: marlapativ/pipelines
    tag: v1.2.1
    pullPolicy: Always
  tolerations:
    - key: 'nvidia.com/gpu'
      operator: 'Exists'
      effect: 'NoSchedule'
  resources:
    requests:
      memory: 256Mi
      cpu: 250m
    limits:
      memory: 512Mi
      cpu: 500m
  extraEnvVars:
    - name: LLAMAINDEX_OLLAMA_BASE_URL
      value: 'http://open-webui-ollama.llm.svc.cluster.local:11434'
    - name: LLAMAINDEX_MODEL_NAME
      value: 'gemma:2b'
    - name: EMBEDDING_DIM
      value: '1024'
    - name: LLAMAINDEX_EMBEDDING_MODEL_NAME
      value: 'mxbai-embed-large:latest'
    - name: DB_HOST
      value: 'postgresql.postgresql.svc.cluster.local'
    - name: DB_PORT
      value: '5432'
    - name: DB_SCHEMA
      value: 'cve'
    - name: DB_TABLE
      value: 'embeddings'
    - name: DB_USER
      valueFrom:
        secretKeyRef:
          name: llm-db-secrets
          key: DB_USER
    - name: DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: llm-db-secrets
          key: DB_PASSWORD
    - name: DB_DATABASE
      valueFrom:
        secretKeyRef:
          name: llm-db-secrets
          key: DB_DATABASE

tolerations:
  - key: 'nvidia.com/gpu'
    operator: 'Exists'
    effect: 'NoSchedule'
resources:
  requests:
    memory: 256Mi
    cpu: 250m
  limits:
    memory: 512Mi
    cpu: 500m
